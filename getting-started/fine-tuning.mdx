---
title: 'Fine-Tuning Models on Oxen.ai'
sidebarTitle: üìñ Overview
description: 'Oxen.ai allows you to fine-tune text, image, and video models with a few clicks.'
---

Simply [upload your data](/getting-started/datasets), and we will provision GPU infrastructure and run the fine-tune. When it's done, Oxen.ai will save the fine-tuned model weights directly to your repository, and we spin down the GPU for you. No worrying about run away costs or having to manage your own infrastructure. 

Once the fine-tuning process is complete, you can deploy your model to a dedicated endpoint and use the [inference endpoints](/getting-started/inference) to integrate it into your application. 

<img alt="Fine-Tuning Ox" className="rounded-xl" src="/images/fine_tuning/fine-tune-ox.jpg" />

Oxen.ai automatically [versions](/getting-started/versioning) and manages the raw model weights and datasets, so that you can always track the data that was used to train the model, or download the model to run locally.

## Why Fine-Tune?

Fine-tuning is a great tool to reach for when basic prompting and context engineering fall short. You may need to fine-tune when:

* **Quality** is critical and the model isn't consistently producing correct outputs.
* **Proprietary Data** gives you a unique advantage that generic models can't capture.
* **Latency**  is a deal breaker and you need real-time responses.
* **Throughput** limitations are bottlenecking your application's scalability.
* **Ownership** of the model is important and you want to control your own destiny.
* **Cost** if a foundation model is too expensive for your use case or you want to deploy a smaller model to the edge.

With Oxen.ai, we make it easy to automate the fine-tuning process of LLMs on your own data.

## Modalities

Oxen.ai supports many data types and tasks for fine-tuning.

<CardGroup cols={3}>
  <Card title="Text Generation" icon="file-pen" href="/examples/fine-tuning/text_generation">
    Fine-tune a model to take a user input as text and generate a single response as text.
  </Card>

  <Card title="Chat Completions" icon="message" href="/examples/fine-tuning/chat_completions">
    Fine-tune a model on chat messages to have a conversation with a user.
  </Card>

  <Card title="Image Generation" icon="palette" href="/examples/fine-tuning/image_generation">
    Fine-tune a model to go from text descriptions to images.
  </Card>

  <Card title="Image Editing" icon="paintbrush" href="/examples/fine-tuning/image_editing">
    Fine-tune a model to take a prompt and a reference image and generate a new image.
  </Card>

  <Card title="Video Generation" icon="video" href="/examples/fine-tuning/video_generation">
    Fine-tune a model to take in a prompt and generate a video.
  </Card>
</CardGroup>

{/* ## Examples

Here are specific examples of how fine-tuning can be used to solve real-world problems. From coding agents to opitmizing tool calling for your agent, there are a lot of use cases for fine-tuning.

- [üí¨ Programming Chatbot](/examples/fine-tuning/chatbots)
- ü§ñ Agents -- <em>**Coming soon**</em>
- üìÑ PDF Extraction -- <em>**Coming soon**</em>
- üìû 24/7 Customer Support Agents -- <em>**Coming soon**</em>
- üîç Enterprise Search and Q&A -- <em>**Coming soon**</em>
- üé® Brand-Specific Content Creation -- <em>**Coming soon**</em>
- üìù Automated Report Generation -- <em>**Coming soon**</em>
- ü™õ Quality Control & Anomaly Detection -- <em>**Coming soon**</em> */}

## Start by Uploading a Dataset

To get started, you'll need to create a new repository on Oxen.ai. Once you've created a repository, you can upload your data. The dataset can be in any tabular format including `csv`, `jsonl`, or `parquet`.

<img alt="Fine-Tuning Dataset Upload" className="rounded-xl" src="/images/fine_tuning/fine-tune-upload-file.png" />

Once you have your dataset uploaded, you can query, explore, and make sure that the data is high quality before kicking off the fine-tuning process. Your model will only be as good as the data you train it on.

![Fine-Tuning Dataset](/images/fine_tuning/fine-tune-dataset.png)

When you feel confident that your dataset is ready, use the "Actions" button to select the model you want to fine-tune.

<img alt="Fine-Tuning Dataset" className="rounded-xl" src="/images/fine_tuning/fine-tune-actions.png" />

## Selecting a Model

This will take you to a form where you can select the model you want to fine-tune and the columns you want to use for the fine-tuning process. We support fine-tuning for [text generation](/examples/fine-tuning/text_generation), [image generation](/examples/fine-tuning/image_generation), [image editing](/examples/fine-tuning/image_editing), and [video generation](/examples/fine-tuning/video_generation) with a variety of models.

<img alt="Fine-Tuning Model Selection" className="rounded-xl" src="/images/fine_tuning/fine-tune-model-selection.png" />

<Info>
If you want support for any specific models, data formats, training methods [contact us](https://airtable.com/appDW4XBL7qTihmwi/shrQF72gHTJw8zvie). We are actively working on support for new models and distributed training.
</Info>


## Monitoring the Fine-Tune

Once you have started the fine-tuning process, you can monitor its progress. The dashboard will show you loss over time and token accuracy processed.

<img alt="Fine-Tuning Monitoring" className="rounded-xl" src="/images/fine_tuning/fine-tune-loss.png" />

If you are fine-tuning an [image](/examples/fine-tuning/image_generation) or [video](/examples/fine-tuning/video_generation) generation model, you can view the generated images or videos in the "Samples" tab to get a feel for the model's performance.

<img alt="Fine-Tuning Samples" className="rounded-xl" src="/images/fine_tuning/fine-tune-samples.png" />

Click on the "Info" tab to see the fine-tuning configuration and all the hyper-parameters used. This will include a link to the [dataset version](/getting-started/versioning) you used and the raw model weights for downloading and running locally.

<img alt="Fine-Tuning Samples" className="rounded-xl" src="/images/fine_tuning/fine-tune-info-tab.png" />

## Deploying the Model

Once the model is fine-tuned, you can deploy it to a dedicated endpoint. This will give you a `/chat/completions` api that you can use to test out the model.

<img alt="Fine-Tuning Configuration" className="rounded-xl" src="/images/fine_tuning/fine-tune-deploy-model.png" />

Swap out the model name with the name of the model you want to use.

```bash
curl https://hub.oxen.ai/api/chat/completions -H "Content-Type: application/json" -d '{
    "model":"oxen:my-model-name",
    "messages": [{"role": "user", "content": "What is the best name for a friendly ox?"}],
}'
```

## Using the Model

Once the model is deployed, you can also chat with it using the Oxen.ai chat interface. Learn more about the [chat interface here](/getting-started/inference).

<img alt="Chatting with the Model" className="rounded-xl" src="/images/chat/chat_window_powerful_coffee_chimpanzee.png" />

For image and video generation, you can use the [playground](https://oxen.ai/ai/models) to generate images and videos.

<img alt="Chatting with the Model" className="rounded-xl" src="/images/fine_tuning/model-playground.png" />

## Downloading the Model

If you want access to the raw model weights, you can download them from the repository using the Oxen.ai [Python Library](/getting-started/python) or the [CLI](/getting-started/cli).

Follow the instructions for [installing oxen](/getting-started/install) if you haven't already.

<CodeGroup>

```bash CLI
oxen download my-username/my-repo models/ox-artistic-cyan-elephant/model.safetensors --revision models/ox-artistic-cyan-elephant
```

```python Python
from oxen import RemoteRepo

repo = RemoteRepo("my-username/my-repo")

repo.download("models/ox-artistic-cyan-elephant/model.safetensors", revision="models/ox-artistic-cyan-elephant")
```

</CodeGroup>

<img alt="Fine-Tuning Configuration" className="rounded-xl" src="/images/fine_tuning/fine-tune-model-weights.png" />

## Need Custom Infrastructure?

If you need custom or private deployments in your own VPC or want to train a larger model on distributed infrastructure, [contact us](https://airtable.com/appDW4XBL7qTihmwi/shrQF72gHTJw8zvie) and we can give you a custom deployment.