---
title: 'üìñ How it works'
description: 'Oxen.ai lets you go from datasets to custom models with a few clicks.'
---

Simply [upload your data](/getting-started/datasets), and we will provision GPU infrastructure and run the fine-tune. When it's done, Oxen.ai will save the fine-tuned model weights directly to your repository. You can deploy your model to a dedicated endpoint and use the [inference endpoints](/getting-started/inference) to test it out. Model weights and datasets are [versioned](/getting-started/versioning) so that you can always track the data that was used to train the model.

<img alt="Fine-Tuning Ox" className="rounded-xl" src="/images/fine_tuning/fine-tune-ox.jpg" />

Once the fine-tuning process is complete, you can [deploy the model](/getting-started/inference) and start using it in your application.

## Why Fine-Tune?

Fine-tuning is a great tool to reach for when basic prompting and context engineering fall short. You may need to fine-tune when:

* **Quality** is critical and the model isn't consistently producing correct outputs.
* **Proprietary Data** gives you a unique advantage that generic models can't capture.
* **Latency**  is a deal breaker and you need real-time responses.
* **Throughput** limitations are bottlenecking your application's scalability.
* **Ownership** of the model is important and you want to control your own destiny.
* **Cost** if a foundation model is too expensive for your use case or you want to deploy a smaller model to the edge.

With Oxen.ai, we make it easy to automate the fine-tuning process of LLMs on your own data.

## Tasks

Oxen.ai supports many data types and tasks for fine-tuning.

<CardGroup cols={4}>
  <Card title="Text Generation" icon="headphones" href="/examples/fine-tuning/text_generation">
    Train a model to take a user input as text and generate a response as text.
  </Card>

  <Card title="Image Generation" icon="palette" href="/examples/fine-tuning/image_generation">
    Train a model to go from text descriptions to images.
  </Card>

  <Card title="Image Editing" icon="palette" href="/examples/fine-tuning/image_editing">
    Train a model to take a prompt and a reference image and generate a new image.
  </Card>

  <Card title="Video Generation" icon="palette" href="/examples/fine-tuning/video_generation">
    Train a model to take in a prompt and generate a video.
  </Card>
</CardGroup>

{/* ## Examples

Here are specific examples of how fine-tuning can be used to solve real-world problems. From coding agents to opitmizing tool calling for your agent, there are a lot of use cases for fine-tuning.

- [üí¨ Programming Chatbot](/examples/fine-tuning/chatbots)
- ü§ñ Agents -- <em>**Coming soon**</em>
- üìÑ PDF Extraction -- <em>**Coming soon**</em>
- üìû 24/7 Customer Support Agents -- <em>**Coming soon**</em>
- üîç Enterprise Search and Q&A -- <em>**Coming soon**</em>
- üé® Brand-Specific Content Creation -- <em>**Coming soon**</em>
- üìù Automated Report Generation -- <em>**Coming soon**</em>
- ü™õ Quality Control & Anomaly Detection -- <em>**Coming soon**</em> */}

## Start by Uploading a Dataset

To get started, you'll need to create a new repository on Oxen.ai. Once you've created a repository, you can upload your data. The dataset can be in any tabular format including `csv`, `jsonl`, or `parquet`.

<img alt="Fine-Tuning Dataset Upload" className="rounded-xl" src="/images/fine_tuning/fine-tune-upload-file.png" />

Once you have your dataset uploaded, you can query, explore, and make sure that the data is high quality before kicking off the fine-tuning process. Your model will only be as good as the data you train it on.

![Fine-Tuning Dataset](/images/fine_tuning/fine-tune-dataset.png)

When you feel confident that your dataset is ready, use the "Actions" button to select the model you want to fine-tune.

<img alt="Fine-Tuning Dataset" className="rounded-xl" src="/images/fine_tuning/fine-tune-actions.png" />

## Selecting a Model

This will take you to a form where you can select the model you want to fine-tune and the columns you want to use for the fine-tuning process. We support fine-tuning for [text generation](/examples/fine-tuning/text_generation), [image generation](/examples/fine-tuning/image_generation), [image editing](/examples/fine-tuning/image_editing), and [video generation](/examples/fine-tuning/video_generation) with a variety of models.

<img alt="Fine-Tuning Model Selection" className="rounded-xl" src="/images/fine_tuning/fine-tune-model-selection.png" />

<Info>
If you want support for any specific models, data formats, training methods [contact us](https://airtable.com/appDW4XBL7qTihmwi/shrQF72gHTJw8zvie). We are actively working on support for new models and distributed training.
</Info>


## Monitoring the Fine-Tune

Once you have started the fine-tuning process, you can monitor its progress. The dashboard will show you loss over time and token accuracy processed.

<img alt="Fine-Tuning Monitoring" className="rounded-xl" src="/images/fine_tuning/fine-tune-loss.png" />

If you are fine-tuning an [image](/examples/fine-tuning/image_generation) or [video](/examples/fine-tuning/video_generation) generation model, you can view the generated images or videos in the "Samples" tab to get a feel for the model's performance.

<img alt="Fine-Tuning Samples" className="rounded-xl" src="/images/fine_tuning/fine-tune-samples.png" />

Click on the "Info" tab to see the fine-tuning configuration and all the hyper-parameters used. This will include a link to the [dataset version](/getting-started/versioning) you used and the raw model weights for downloading and running locally.

<img alt="Fine-Tuning Samples" className="rounded-xl" src="/images/fine_tuning/fine-tune-info-tab.png" />

## Deploying the Model

Once the model is fine-tuned, you can deploy it to a dedicated endpoint. This will give you a `/chat/completions` api that you can use to test out the model.

<img alt="Fine-Tuning Configuration" className="rounded-xl" src="/images/fine_tuning/fine-tune-deploy-model.png" />

Swap out the model name with the name of the model you want to use.

```bash
curl https://hub.oxen.ai/api/chat/completions -H "Content-Type: application/json" -d '{
    "model":"oxen:my-model-name",
    "messages": [{"role": "user", "content": "What is the best name for a friendly ox?"}],
}'
```

## Using the Model

Once the model is deployed, you can also chat with it using the Oxen.ai chat interface. Learn more about the [chat interface here](/getting-started/inference).

<img alt="Chatting with the Model" className="rounded-xl" src="/images/chat/chat_window_powerful_coffee_chimpanzee.png" />

For image and video generation, you can use the [playground](https://oxen.ai/ai/models) to generate images and videos.

<img alt="Chatting with the Model" className="rounded-xl" src="/images/fine_tuning/model-playground.png" />

## Downloading the Model

If you want access to the raw model weights, you can download them from the repository using the Oxen.ai [Python Library](/getting-started/python) or the [CLI](/getting-started/cli).

Follow the instructions for [installing oxen](/getting-started/install) if you haven't already.

<CodeGroup>

```bash CLI
oxen download my-username/my-repo models/ox-artistic-cyan-elephant/model.safetensors --revision models/ox-artistic-cyan-elephant
```

```python Python
from oxen import RemoteRepo

repo = RemoteRepo("my-username/my-repo")

repo.download("models/ox-artistic-cyan-elephant/model.safetensors", revision="models/ox-artistic-cyan-elephant")
```

</CodeGroup>

<img alt="Fine-Tuning Configuration" className="rounded-xl" src="/images/fine_tuning/fine-tune-model-weights.png" />

## Need Custom Infrastructure?

If you need custom or private deployments in your own VPC or want to train a larger model on distributed infrastructure, [contact us](https://airtable.com/appDW4XBL7qTihmwi/shrQF72gHTJw8zvie) and we can give you a custom deployment.