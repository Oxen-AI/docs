---
title: ğŸ‚ Oxen.ai
description: Infrastructure for collaborating on datasets and fine-tuning open source models.
---

<img alt="Oxen.ai Moon Ox Hero" className="rounded-xl" classname="block" src="/images/MoonOx.png" />

Oxen.ai gives you the tools to fine-tune open source [models](/getting-started/inference) on your own data. We believe that your data is your differentiator, and training models on your own data should be easy, fast, and approachable for everyone.

The platform makes it easy to spin up GPU infrastructure to [train models](/examples/notebooks/train_llm) or run [inference](/getting-started/inference) at scale. The [datasets](/getting-started/datasets) and [models weights](/getting-started/fine-tuning) are all [versioned](/getting-started/versioning) and stored in an Oxen.ai [repository](/getting-started/versioning) for easy iteration, comparison, and collaboration with your team.

## âœ… Features

Oxen.ai allows you to own your model end to end, from curating datasets to fine-tuning models to deploying them at scale. Start by trying out the latest and greatest open source [LLM](/examples/inference/chat_completions), [video generation](/examples/inference/video_generation), or [image editing](/examples/inference/image_editing) models, then graduate to [fine-tuning](/getting-started/fine-tuning) your own models.

* âš¡ï¸ [Inference APIs](/getting-started/inference) - Quickly iterate on prompts and models for many modalities
  * [ğŸ’¬ LLMs](/examples/inference/chat_completions) - Generate and understand text and images responses
  * [ğŸ–¼ï¸ Image Generation](/examples/inference/image_generation) - Generate images from prompts
  * [ğŸ¨ Image Editing](/examples/inference/image_editing) - Edit images with prompts
  * [ğŸ¥ Video Generation](/examples/inference/video_generation) - Generate videos from prompts
* âš™ï¸ [Fine-Tuning](/getting-started/fine-tuning) - Go from dataset to deployable model in a few clicks
* ğŸ“Š [Datasets](/getting-started/datasets) - Build datasets for training, fine-tuning, or evaluating models
* ğŸš€ [Batch Inference](/getting-started/evaluation) - Run your model at scale over large datasets, to label data, generate synthetic data or evaluate model performance

### âš¡ **Model Inference**

Whether you are making your first LLM call or need to deploy a fine-tuned model, [Oxen.ai](http://Oxen.ai) gives you the flexibility to swap models through a unified [model inference API](/getting-started/inference). The API is OpenAI compatible and supports a variety of foundation models as well as fine-tunable models. See the list of [supported models](https://oxen.ai/ai/models) to get started.

<img alt="Oxen.ai Chat Window" className="rounded-xl" src="/images/chat/chat_window.png" />

The while calling inference API is a great place to start, the real power of Oxen.ai is being able to take an open source model and [fine-tune](/getting-started/fine-tuning) it on your own data, optimizing it for accuracy, speed, or quality. Once it's fine-tuned, you can deploy it to the same interface in minutes. No DevOps or MLOps experience required.

### âš™ï¸ **Fine-Tune Models**

The best models are the ones that understand your context and continue to learn from your data over time.

Go from dataset to model in a few clicks with Oxen.ai's fine-tuning tooling. Select a dataset, define your inputs and outputs, and let Oxen.ai do the grunt work. Oxen saves model weights to it's version store tying model weights to the dataset and code that was used to train them.

<img alt="Fine-Tuning" src="/images/fine_tuning/fine-tune-home.png" />

Once the model has been fine-tuned, you can easily deploy the model behind an inference endpoint and start the evaluation loop over again.

### ğŸ“Š **Build Datasets**

Quality datasets are the difference between prototypes and production models. Collaborate on multi-modal datasets used for training, fine-tuning, or evaluating models. Backed by Oxen.ai's [version control](https://github.com/Oxen-AI/Oxen), you'll never worry about remembering what data a model was trained or evaluated on.

Learn how to interface with datasets in the [Oxen Python Library](/getting-started/python) or more about supported dataset types and formats [here](/getting-started/datasets).

<img alt="Image Net" className="rounded-xl" src="/images/datasets/image_net_train.png" />

### ğŸš€ **Run Models at Scale**

Find the best model and prompt for your use case. Leverage your own datasets to build custom evaluations. Evaluation results are versioned and saved as datasets in the repository for easy performance tracking over time.

<img alt="Run Models on Datasets" className="rounded-xl" src="/images/rmod.png" />

### ğŸ’¾ **Version Control**

The through line of Oxen.ai is that all model weights, datasets, and code are versioned and can be stored in a single repository. This makes it easy to track changes, compare models, and share datasets with your team. You can interact with the repository through the [command line interface](/getting-started/cli), [python library](/getting-started/python), or web interface.

We built the version control system to be [blazing fast](/features/performance), [open source](https://github.com/Oxen-AI/Oxen), and extensible for anyone to build upon. It can be used to version any type of data, not just machine learning datasets. It scales up to monorepos with [millions of files and terabytes of data](/features/performance).

## ğŸ”’ Own Your AI

At Oxen.ai, we believe you should **own your AI, don't rent it**. Own your AI by training models on your data and downloading the weights for your applications. For image or video generation, create high-quality LoRAs and deploy to ComfyUI. For language models, optimize for speed, cost, or privacy and deploy to Ollama or vLLM.

Don't want to host your own infrastructure? Oxen.ai also offers a [managed service](/examples/inference/deploying_models) for deploying models at scale.

## ğŸŒ¾ Why Build Oxen?

Oxen was built by a team of machine learning engineers, who have spent countless hours in their careers managing datasets and training models. We have used many different tools, but none of them were as easy to use and as ergonomic as we would like. 

Production grade AI applications are constantly juggling models, datasets, and code, and it's easy to get lost. Let alone the late nights installing the proper cuda and pytorch versions. If you have every been stuck syncing massive model weights, datasets, or aligning them with the code that was used to train them, we feel your pain.

Oxen is the tool we wish we had to abstract away the infrastructure and focus on the fun parts of building AI applications.

## ğŸ‚ Why the name Oxen?

â€œOxenâ€ comes from the fact that we take care of the grunt work of the infrastructure for you. Oxen love will plow, maintain, and version your data and models like a good farmer tends to their fields ğŸŒ¾. During the agricultural revolution, the oxen pulling plows offloaded work and helped people specialize and start working on other important societal tasks. Let Oxen take care of the heavy infrastructure work so you can focus on solving the higher-level problems that matter to your product.