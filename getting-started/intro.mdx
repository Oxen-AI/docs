---
title: 🐂 Oxen.ai
description: Infrastructure to fine-tune better, faster, and cheaper AI models.
---

<img alt="Oxen.ai Moon Ox Hero" className="rounded-xl" classname="block" src="/images/MoonOx.png" />

Oxen.ai gives you the tools to build the best [model](/getting-started/inference) for your use case. Our core belief is that you should **own your AI, don't rent it**.

The platform makes it easy to spin up GPU infrastructure to [train models](/examples/notebooks/train_llm) or run [inference](/getting-started/inference) at scale. When you are done, the [datasets](/getting-started/datasets) and [models weights](/getting-started/fine-tuning) are all [versioned](/getting-started/versioning) and stored in an Oxen.ai [repository](/getting-started/versioning) for easy iteration, comparison, and collaboration.

## ✅ Features

Test out [prompts](/getting-started/inference) on closed source models or [fine-tune](/getting-started/fine-tuning) your own models. Once you have a model you love, run the model at scale with [batch inference](/getting-started/evaluation).

* ⚡️ [Inference](/getting-started/inference) - Quickly iterate on prompts and models
* ⚙️ [Fine-Tuning](/getting-started/fine-tuning) - Go from dataset to deployable model in a few clicks
* 📊 [Datasets](/getting-started/datasets) - Build datasets for training, fine-tuning, or evaluating models
* 🚀 [Batch Inference](/getting-started/evaluation) - Run your model at scale over large datasets, to label data, generate synthetic data or evaluate performance
* 💾 [Version Control](/getting-started/versioning) - Sync your datasets, model weights, and code with a collaborative hub

With Oxen's open source [data version control system](/getting-started/versioning), you have access to the raw model weights, datasets, and code through the [command line interface](/getting-started/cli), [python library](/python-api/index) or [HTTP API](/http-api/index). This makes it seamless to integrate prompts, models, and datasets into your existing workflows.

### ⚡ **Model Inference**

Whether you are making your first LLM call or need to deploy a fine-tuned model, [Oxen.ai](http://Oxen.ai) gives you the flexibility to swap models through a unified [Model API](/getting-started/inference). The interface is OpenAI compatible and supports foundation models from Anthropic, Google, Meta, and OpenAI. See the list of [supported models](https://oxen.ai/ai/models) to get started.

Closed source models not working for your use case? [Fine-tune your own model](/getting-started/fine-tuning), optimizing it for accuracy, speed, or cost, and deploy it to the same interface in minutes.

<img alt="Oxen.ai Chat Window" className="rounded-xl" src="/images/chat/chat_window.png" />

### ⚙️ **Fine-Tune Models**

The best models are the ones that understand your context and continue to learn from your data over time.

Go from dataset to model in a few clicks with Oxen.ai's fine-tuning tooling. Select a dataset, define your inputs and outputs, and let Oxen.ai do the grunt work. Oxen saves model weights to it's version store tying model weights to the dataset and code that was used to train them.

<img alt="Fine-Tuning" src="/images/fine_tuning/fine-tune-home.png" />

Once the model has been fine-tuned, you can easily deploy the model behind an inference endpoint and start the evaluation loop over again.

### 📊 **Build Datasets**

Quality datasets are the difference between prototypes and production models. Collaborate on multi-modal datasets used for training, fine-tuning, or evaluating models. Backed by Oxen.ai's [version control](https://github.com/Oxen-AI/Oxen), you'll never worry about remembering what data a model was trained or evaluated on.

Learn how to interface with datasets in the [Oxen Python Library](/getting-started/python) or more about supported dataset types and formats [here](/getting-started/datasets).

<img alt="Image Net" className="rounded-xl" src="/images/datasets/image_net_train.png" />

### 🚀 **Run Models at Scale**

Find the best model and prompt for your use case. Leverage your own datasets to build custom evaluations. Evaluation results are versioned and saved as datasets in the repository for easy performance tracking over time.

<img alt="Run Models on Datasets" className="rounded-xl" src="/images/rmod.png" />

### 💾 **Version Control**

The through line of Oxen.ai is that all model weights, datasets, and code are versioned and can be stored in a single repository. This makes it easy to track changes, compare models, and share datasets with your team. You can interact with the repository through the [command line interface](/getting-started/cli), [python library](/getting-started/python), or web interface.

We built the version control system to be [blazing fast](/features/performance), [open source](https://github.com/Oxen-AI/Oxen), and extensible for anyone to build upon. It can be used to version any type of data, not just machine learning datasets. It scales up to monorepos with [millions of files and terabytes of data](/features/performance).

## 🌾 Why Build Oxen?

One of Oxen.ai's core values is that you should *own your AI, don't rent it*.

Oxen was built by a team of machine learning engineers, who have spent countless hours in their careers managing datasets and training models. We have used many different tools, but none of them were as easy to use and as ergonomic as we would like. 

Production grade AI applications are constantly juggling models, datasets, and code, and it's easy to get lost. If you have every been stuck syncing massive model weights, datasets, or aligning them with the code that was used to train them, we feel your pain.

Oxen is the tool we wish we had.

## 🐂 Why the name Oxen?

“Oxen” comes from the fact that we take care of the grunt work of the infrastructure for you. Oxen love will plow, maintain, and version your data and models like a good farmer tends to their fields 🌾. During the agricultural revolution, the oxen pulling plows offloaded work and helped people specialize and start working on other important societal tasks. Let Oxen take care of the heavy infrastructure work so you can focus on solving the higher-level problems that matter to your product.