---
title: 🐂 What is Oxen?
description: 'Oxen.ai is an easy-to-use developer platform for fine-tuning AI on your own data.'
---

<img alt="Oxen.ai Moon Ox Hero" classname="block" src="/images/MoonOx.png" />

Oxen.ai enables you to build proprietary models faster, without worrying about infrastructure. Deploy your model to a GPU to [test prompts and context](/getting-started/inference) using a unified API. Quickly [build your own evals](/getting-started/evaluation) to find the best model and prompt for your use case. When you're ready, [kick off fine-tuning](/getting-started/fine-tuning) loops with your own domain-specific data. It's flexible when you need it, abstracted when you don't.

## ✅ Features

* ⚡️ [Inference](/getting-started/inference) - Quickly iterate on prompts and models
* 🚀 [Fine-Tuning](/features/fine-tuning) - Go from dataset to deployable model in a few clicks
* 📊 [Datasets](/features/datasets) - Build datasets for training, fine-tuning, or evaluating models
* 🔬 [Evaluation](/features/evaluation) - Find the best model and prompt given your dataset and use case
* 📓 [Notebooks](/features/notebooks) - Write custom code to interact with your datasets and models
* 💾 [Version Control](/features/versioning) - Sync your datasets, model weights, and code with a collaborative hub

With easy-to-use developer tools, you have access to the raw model weights, code and datasets through the [command line interface](/getting-started/cli), [python library](/getting-started/python). This makes it easy to integrate Oxen into your existing workflows and train on your own private data.

Under the hood, [Oxen.ai](http://Oxen.ai) is built on server-less GPU infrastructure connected to it's blazing fast open source [version control system](https://github.com/Oxen-AI/oxen-release). The Oxen.ai core can handle millions of files and terabytes of data in a single monorepo. To learn more about the size and scale of datasets that Oxen.ai can support checkout [our benchmarks](/features/performance). 

### ⚡ **Quickly Iterate on Models**

Whether you are making your first LLM call or need to deploy a fine-tuned model, [Oxen.ai](http://Oxen.ai) gives you the flexibility to swap models through a unified [Model API](/features/chat). The interface is OpenAI compatible and supports foundation models from Anthropic, Google, Meta, and OpenAI. 

Closed source models not working for your use case? Fine-tune your own model, optimizing it for speed, privacy or cost, and deploy it to the same interface in minutes. See the list of [supported models](https://oxen.ai/ai/models) to get started.

<img alt="Oxen.ai Chat Window" className="rounded-xl" src="/images/chat/chat_window.png" />

### 🚀 **Fine-Tune Models**

Go from dataset to model in a few clicks with Oxen.ai's fine-tuning tooling. Select a dataset, define your inputs and outputs, and let Oxen.ai do the grunt work. Oxen saves model weights to it's version store tying model weights to the dataset and code that was used to train them. 

Once the model has been fine-tuned, you can easily deploy the model behind an inference endpoint and start the evaluation loop over again.

<img alt="Fine-Tuning" src="/images/fine_tuning/fine-tune-home.png" />

### 📊 **Build Datasets**

Quality datasets are the difference between prototypes and production models. Collaborate on multi-modal datasets used for training, fine-tuning, or evaluating models. Backed by Oxen.ai's [version control](https://github.com/Oxen-AI/oxen-release), you'll never worry about remembering what data a model was trained or evaluated on. 

Learn how to interface with datasets in the [Oxen Python Library](/getting-started/python) or more about supported dataset types and formats [here](/features/datasets).

<img alt="Image Net" className="rounded-xl" src="/images/datasets/image_net_train.png" />

### 🔬 **Evaluate Models**

Find the best model and prompt for your use case. Leverage your own datasets to build custom evaluations. Evaluation results are versioned and saved as datasets in the repository for easy performance tracking over time.

<img alt="Run Models on Datasets" className="rounded-xl" src="/images/rmod.png" />

### 📓 **Write Notebooks**

Spin up a [Marimo Notebook](https://marimo.io) on a GPU or CPU in seconds. Use the [Oxen Python Library](/getting-started/python) to interact with your datasets and models. Write custom code to process your data, visualize distributions, compute metrics, and even train models.

<img alt="Notebook" className="rounded-xl" src="/images/marimo/synthetic-data/df_and_graph.png" />

### 💾 **Version Control**

The through line of Oxen.ai is that all model weights, datasets, and code are versioned and can be stored in a single repository. This makes it easy to track changes, compare models, and share datasets with your team. You can interact with the repository through the [command line interface](/getting-started/cli), [python library](/getting-started/python), or web interface.

We built the version control system to be open source and extensible for anyone to build upon. It can be used to version any type of data, not just machine learning datasets. It scales up to monorepos with [millions of files and terabytes of data](/features/performance). 

The core Oxen.ai version control system shines at workflows and data sizes that git or git-lfs fall short. The interface is inspired by git, so that it is easy to learn, but has a few core differences (TODO: Differences page). Oxen is built from the ground up to handle large datasets with many files or large csvs, parquet files, or other large binary blobs.

## 🌾 Why Build Oxen?

Oxen was built by a team of machine learning engineers, who have spent countless hours in their careers managing datasets and training models. We have used many different tools, but none of them were as easy to use and as ergonomic as we would like. 

Production grade AI applications are constantly juggling models, datasets, and code, and it's easy to get lost. If you have every been stuck syncing massive model weights, datasets, or aligning them with the code that was used to train them, we feel your pain.

Oxen is here to do the grunt work, so that you can focus on what matters, shipping great models.

## 🐂 Why the name Oxen?

“Oxen” comes from the fact that we will plow, maintain, and version your data like a good farmer tends to their fields 🌾. During the agricultural revolution, the plow and offloading work to Oxen helped people specialize and start working on other important societal tasks. Let Oxen take care of the grunt work of your infrastructure so you can focus on solving the higher-level problems that matter to your product.